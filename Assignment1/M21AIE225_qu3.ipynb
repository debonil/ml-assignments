{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(actual, pred):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == 1:\n",
    "            if pred[i] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        else:\n",
    "            if pred[i] ==1:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "\n",
    "    return [[tp, fn],[ fp, tn]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, target, test_size=0.2, random_state=41):\n",
    "    trainX = df.sample(frac=test_size, random_state=random_state)\n",
    "    testX = df.drop(trainX.index)\n",
    "    trainY = target.sample(frac=test_size, random_state=random_state)\n",
    "    testY = target.drop(trainY.index)\n",
    "    return trainX, testX, trainY, testY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index: float = None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "        self.value = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_samples_split=0, max_depth=0):\n",
    "        self.root = None\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "\n",
    "        X, Y = dataset[:, :-1], dataset[:, -1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "\n",
    "        if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
    "\n",
    "            best_split = self.get_best_split(\n",
    "                dataset, num_samples, num_features)\n",
    "\n",
    "            if best_split[\"info_gain\"] > 0:\n",
    "\n",
    "                left_subtree = self.build_tree(\n",
    "                    best_split[\"dataset_left\"], curr_depth+1)\n",
    "\n",
    "                right_subtree = self.build_tree(\n",
    "                    best_split[\"dataset_right\"], curr_depth+1)\n",
    "\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"],\n",
    "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "\n",
    "        return Node(value=leaf_value)\n",
    "\n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "\n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "\n",
    "            for threshold in possible_thresholds:\n",
    "\n",
    "                dataset_left, dataset_right = self.split(\n",
    "                    dataset, feature_index, threshold)\n",
    "\n",
    "                if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
    "                    y, left_y, right_y = dataset[:, -\n",
    "                                                 1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "\n",
    "                    curr_info_gain = self.information_gain(y, left_y, right_y)\n",
    "\n",
    "                    if curr_info_gain > max_info_gain:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"info_gain\"] = curr_info_gain\n",
    "                        max_info_gain = curr_info_gain\n",
    "\n",
    "        return best_split\n",
    "\n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "\n",
    "        dataset_left = np.array(\n",
    "            [row for row in dataset if row[feature_index] <= threshold])\n",
    "        dataset_right = np.array(\n",
    "            [row for row in dataset if row[feature_index] > threshold])\n",
    "        return dataset_left, dataset_right\n",
    "\n",
    "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
    "\n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        if mode == \"gini\":\n",
    "            gain = self.gini_index(\n",
    "                parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n",
    "        else:\n",
    "            gain = self.entropy(\n",
    "                parent) - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n",
    "        return gain\n",
    "\n",
    "    def entropy(self, y):\n",
    "\n",
    "        class_labels = np.unique(y)\n",
    "        entropy = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            entropy += -p_cls * np.log2(p_cls)\n",
    "        return entropy\n",
    "\n",
    "    def gini_index(self, y):\n",
    "\n",
    "        class_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            gini += p_cls**2\n",
    "        return 1 - gini\n",
    "\n",
    "    def calculate_leaf_value(self, Y):\n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "\n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "\n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.feature_index), \"<=\",\n",
    "                  tree.threshold, \"?\", tree.info_gain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "\n",
    "        print(X.shape)\n",
    "        print(Y.shape)\n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "\n",
    "    def predict(self, X):\n",
    "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return preditions\n",
    "\n",
    "    def make_prediction(self, x, tree):\n",
    "\n",
    "        if tree.value != None:\n",
    "            return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val <= tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)\n",
    "\n",
    "    def score(self, X, Y):\n",
    "\n",
    "        print(X.shape)\n",
    "        print(Y.shape)\n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>weight</th>\n",
       "      <th>skincolor</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>0.571539</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>5.348117</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>3.419377</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>3.323665</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>1.453573</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size    weight  skincolor  target\n",
       "0    35  0.571539        139       0\n",
       "1    23  5.348117        184       0\n",
       "2    38  3.419377        126       0\n",
       "3    34  3.323665        137       0\n",
       "4    34  1.453573        198       0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data-ques-3\\dataset.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['target']\n",
    "df1 = df.copy()\n",
    "df1 = df1.drop('target', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training split input-  (40, 3)\n",
      "Training split input-  (40,)\n",
      "Testing split input-  (160, 3)\n",
      "Testing split input-  (160,)\n",
      "     size    weight  skincolor\n",
      "96     24  2.324527        202\n",
      "63     17  5.832351        159\n",
      "168    18  0.616260        287\n",
      "196    21  0.543074        160\n",
      "68     22  5.488565        181\n",
      "96     0\n",
      "63     0\n",
      "168    1\n",
      "196    1\n",
      "68     0\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data - 80:20 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df1, target, test_size=0.2, random_state=41)\n",
    "print(\"Training split input- \", X_train.shape)\n",
    "print(\"Training split input- \", y_train.shape)\n",
    "print(\"Testing split input- \", X_test.shape)\n",
    "print(\"Testing split input- \", y_test.shape)\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 3)\n",
      "(40, 1)\n",
      "Decision Tree Classifier Created\n"
     ]
    }
   ],
   "source": [
    "# Defining the decision tree algorithm\n",
    "dtree = DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
    "dtree.fit(X_train.values, y_train.values.reshape(-1, 1))\n",
    "print('Decision Tree Classifier Created')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report - \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90        80\n",
      "           1       0.93      0.86      0.90        80\n",
      "\n",
      "    accuracy                           0.90       160\n",
      "   macro avg       0.90      0.90      0.90       160\n",
      "weighted avg       0.90      0.90      0.90       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting the values of test data\n",
    "y_pred = dtree.predict(X_test.values)\n",
    "print(\"Classification report - \\n\",\n",
    "      classification_report(y_test.values.reshape(-1, 1), y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69, 11], [5, 75]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(24.0, 0.5, 'Actual label')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test.values.reshape(-1, 1), y_pred)\n",
    "print(cm)\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(data=cm, linewidths=.5, annot=True, square=True,  cmap='Blues')\n",
    "plt.ylabel('Actual label')\n",
    "#all_sample_title = 'Accuracy Score: {0}'.format(dtree.score(X_test, y_test))\n",
    "#plt.title(all_sample_title, size = 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_1 <= 0.79519665 ? 0.7582766571931676\n",
      " left:X_0 <= 25.0 ? 0.4394969869215134\n",
      "  left:1.0\n",
      "  right:0.0\n",
      " right:0.0\n"
     ]
    }
   ],
   "source": [
    "# Visualising the graph without the use of graphvizplt.figure(figsize = (20,20))\n",
    "dtree.print_tree()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
